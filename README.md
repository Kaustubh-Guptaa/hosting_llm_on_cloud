## LLM Inference Architecture
<i>
  FastAPI Wrapper over vLLM Model Server
</i>
<img width="1768" height="353" alt="LLM Deployment" src="https://github.com/user-attachments/assets/22d0806a-3bf7-47ae-afa2-b364de317fce" />
